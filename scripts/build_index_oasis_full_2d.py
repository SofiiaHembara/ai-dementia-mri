#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
build_index_oasis_full_2d.py

–ë—É–¥—É—î –ø–æ–≤–Ω–∏–π 2D-—ñ–Ω–¥–µ–∫—Å –¥–ª—è OASIS:
- –æ–±—Ö–æ–¥–∏—Ç—å data/raw/disc*/OAS1_XXXX_MR1
- –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å—É–±'—î–∫—Ç–∞ –±–µ—Ä–µ –æ–±—Ä–æ–±–ª–µ–Ω–∏–π .img (–∞–±–æ RAW fallback)
- —Ä—ñ–∂–µ –æ–±'—î–º –Ω–∞ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ñ –æ—Å–º–∏—Å–ª–µ–Ω—ñ —Å–ª–∞–π—Å–∏
- –∑–±–µ—Ä—ñ–≥–∞—î PNG —É data/processed/oasis_full_2d/<subject_id>/
- —Å—Ç–≤–æ—Ä—é—î data/index_oasis_full_2d.csv –∑ –∫–æ–ª–æ–Ω–∫–∞–º–∏:
    subject_id, slice_path, label, split

label:
- non_demented  : CDR == 0
- dementia      : CDR > 0
"""

from __future__ import annotations
import argparse
from pathlib import Path
import os

import numpy as np
import pandas as pd
import nibabel as nib
from sklearn.model_selection import train_test_split
from tqdm import tqdm
from PIL import Image


def find_subject_dirs(nifti_root: Path) -> list[Path]:
    """
    –®—É–∫–∞—î –≤—Å—ñ –ø–∞–ø–∫–∏ OAS1_XXXX_MR1 –≤ disc* –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ nifti_root.
    """
    subj_dirs: list[Path] = []
    for disc in sorted(nifti_root.glob("disc*")):
        if not disc.is_dir():
            continue
        for subj in sorted(disc.glob("OAS1_*_MR1")):
            if subj.is_dir():
                subj_dirs.append(subj)
    return subj_dirs


def choose_img_path(subj_dir: Path) -> Path | None:
    """
    –û–±–∏—Ä–∞—î –æ–¥–∏–Ω .img –¥–ª—è –¥–∞–Ω–æ–≥–æ —Å—É–±'—î–∫—Ç–∞:
    1) PROCESSED/MPRAGE/T88_111/*masked_gfc.img (–Ω–∞–π–∫—Ä–∞—â–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç)
    2) PROCESSED/MPRAGE/T88_111/*.img
    3) RAW/*mpr-1_anon.img

    –Ø–∫—â–æ –Ω—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ ‚Äî –ø–æ–≤–µ—Ä—Ç–∞—î None.
    """
    # 1) masked_gfc
    cand1 = sorted(
        subj_dir.glob(
            "PROCESSED/MPRAGE/T88_111/*masked_gfc.img"
        )
    )
    if cand1:
        return cand1[0]

    # 2) –±—É–¥—å-—è–∫–∏–π .img –∑ T88_111
    cand2 = sorted(subj_dir.glob("PROCESSED/MPRAGE/T88_111/*.img"))
    if cand2:
        return cand2[0]

    # 3) RAW mpr-1_anon
    cand3 = sorted(subj_dir.glob("RAW/*mpr-1_anon.img"))
    if cand3:
        return cand3[0]

    return None


def load_volume(img_path: Path) -> np.ndarray:
    """
    –ß–∏—Ç–∞—î .img/.hdr —è–∫ –æ–±'—î–º (X, Y, Z) —É float32.
    """
    img = nib.load(str(img_path))
    data = img.get_fdata().astype(np.float32)
    # —ñ–Ω–æ–¥—ñ dim –ø–æ—Ä—è–¥–æ–∫ –º–æ–∂–µ –±—É—Ç–∏ –Ω–µ (X,Y,Z), –∞–ª–µ –¥–ª—è –Ω–∞—à–æ–≥–æ –¥–µ–º–æ —Ü—å–æ–≥–æ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ
    return data


def slice_volume_to_pngs(
    vol: np.ndarray,
    subject_id: str,
    out_root: Path,
    axis: int = 2,
    keep_mid_fraction: float = 0.6,
    min_dynamic_range: float = 1e-3,
) -> list[Path]:
    """
    –†—ñ–∂–µ 3D-–æ–±'—î–º –Ω–∞ 2D-—Å–ª–∞–π—Å–∏ –π –∑–±–µ—Ä—ñ–≥–∞—î —ó—Ö —è–∫ PNG.

    - axis: –≤–∑–¥–æ–≤–∂ —è–∫–æ—ó –æ—Å—ñ —Ä—ñ–∑–∞—Ç–∏ (2 ‚Äî —Ç–∏–ø–æ–≤–æ –∞–∫—Å—ñ–∞–ª—å–Ω—ñ —Å–ª–∞–π—Å–∏).
    - keep_mid_fraction: —è–∫—É —á–∞—Å—Ç–∏–Ω—É —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–∏—Ö —Å–ª–∞–π—Å—ñ–≤ –ª–∏—à–∏—Ç–∏ (0.6 = 60% –ø–æ —Ü–µ–Ω—Ç—Ä—É).
    - min_dynamic_range: —è–∫—â–æ max-min < threshold, –≤–≤–∞–∂–∞—î–º–æ —Å–ª–∞–π—Å "–ø–æ—Ä–æ–∂–Ω—ñ–º" —ñ –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ.
    """
    vol = np.nan_to_num(vol)

    # –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î–º–æ —Ç–∞–∫, —â–æ–± –≤—ñ—Å—å —Å–ª–∞–π—Å—ñ–≤ –±—É–ª–∞ –æ—Å—Ç–∞–Ω–Ω—å–æ—é
    if axis != vol.ndim - 1:
        vol = np.moveaxis(vol, axis, -1)

    nz = vol.shape[-1]
    if nz < 4:
        return []

    start = int(nz * (1.0 - keep_mid_fraction) / 2.0)
    end = int(nz * (1.0 + keep_mid_fraction) / 2.0)
    start = max(start, 0)
    end = min(end, nz)

    out_dir = out_root / subject_id
    out_dir.mkdir(parents=True, exist_ok=True)

    paths: list[Path] = []
    for idx in range(start, end):
        sl = vol[..., idx]
        sl = np.nan_to_num(sl)

        # üîπ –ö–õ–Æ–ß: —Å—Ç–∏—Å–∫–∞—î–º–æ –≤—Å—ñ singleton-–≤–∏–º—ñ—Ä–∏
        sl = np.squeeze(sl)

        # –ù–∞–º –ø–æ—Ç—Ä—ñ–±–µ–Ω 2D-—Å–ª–∞–π—Å (H, W). –í—Å–µ —ñ–Ω—à–µ ‚Äî —Å–∫—ñ–ø–∞—î–º–æ.
        if sl.ndim != 2:
            print(f"[WARN] Slice {subject_id} z={idx} –º–∞—î —Ñ–æ—Ä–º—É {sl.shape}, –ø—Ä–æ–ø—É—Å–∫–∞—é.")
            continue

        # –§—ñ–ª—å—Ç—Ä –ø–æ –¥–∏–Ω–∞–º—ñ—á–Ω–æ–º—É –¥—ñ–∞–ø–∞–∑–æ–Ω—É (—â–æ–± –≤–∏–∫–∏–Ω—É—Ç–∏ –º–∞–π–∂–µ —á–æ—Ä–Ω—ñ/–∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ñ —Å–ª–∞–π—Å–∏)
        dr = float(sl.max() - sl.min())
        if dr < min_dynamic_range:
            continue

        # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–æ [0, 255]
        sl_norm = sl - sl.min()
        if sl_norm.max() > 0:
            sl_norm = sl_norm / sl_norm.max()
        sl_uint8 = (sl_norm * 255.0).clip(0, 255).astype(np.uint8)

        out_path = out_dir / f"{subject_id}_z{idx:03d}.png"
        try:
            Image.fromarray(sl_uint8).save(out_path)
            paths.append(out_path)
        except Exception as e:
            print(f"[ERROR] –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–±–µ—Ä–µ–≥—Ç–∏ —Å–ª–∞–π—Å {out_path}: {e}")
            continue

    return paths

def load_clinical_labels(clinical_csv: Path) -> dict[str, str]:
    """
    –ß–∏—Ç–∞—î clinical CSV (oasis_cross-sectional.csv) —ñ —Å—Ç–≤–æ—Ä—é—î mapping:
        subject_id -> label ('dementia' / 'non_demented')

    –í–≤–∞–∂–∞—î–º–æ:
        - ID –º–∞—î —Ñ–æ—Ä–º–∞—Ç 'OAS1_0001_MR1'
        - CDR == 0 -> non_demented
        - CDR >  0 -> dementia
    """
    df = pd.read_csv(clinical_csv)
    # –ù–∞–º–∞–≥–∞—î–º–æ—Å—å –∑–Ω–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫—É –∑ ID
    id_col = None
    for cand in ["ID", "id", "Subject ID", "Subject", "MR ID"]:
        if cand in df.columns:
            id_col = cand
            break
    if id_col is None:
        raise ValueError(
            f"–ù–µ –∑–Ω–∞–π—à–ª–∞ –∫–æ–ª–æ–Ω–∫—É –∑ ID –≤ clinical_csv. –Ñ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}"
        )

    if "CDR" not in df.columns:
        raise ValueError("clinical_csv –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 'CDR'.")

    labels: dict[str, str] = {}
    for _, row in df.iterrows():
        sid = str(row[id_col]).strip()
        if not sid:
            continue
        cdr = row["CDR"]
        try:
            cdr_val = float(cdr)
        except Exception:
            continue
        if np.isnan(cdr_val):
            continue

        if cdr_val == 0.0:
            label = "non_demented"
        else:
            label = "dementia"
        labels[sid] = label

    return labels


def stratified_split_subjects(
    subj_df: pd.DataFrame,
    seed: int = 42,
    train_frac: float = 0.6,
    val_frac: float = 0.2,
) -> dict[str, str]:
    """
    –†–æ–±–∏—Ç—å patient-level split –∑ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—é —Å—Ç—Ä–∞—Ç—ñ—Ñ—ñ–∫–∞—Ü—ñ—î—é.
    –ü–æ–≤–µ—Ä—Ç–∞—î dict: subject_id -> split ('train'/'val'/'test').

    –†–æ–±–∏–º–æ:
        - train / temp  (temp ~ val+test, 40%)
        - temp -> val / test (50/50 –≤—ñ–¥ temp)
    –Ø–∫—â–æ —Å—Ç—Ä–∞—Ç—ñ—Ñ—ñ–∫–∞—Ü—ñ—è –Ω–µ–º–æ–∂–ª–∏–≤–∞ (–º–∞–ª–æ –∑—Ä–∞–∑–∫—ñ–≤) ‚Äî fallback –Ω–∞ non-stratified split.
    """
    assert abs(train_frac + val_frac - 0.8) < 1e-6, "train_frac + val_frac –º–∞—î –±—É—Ç–∏ 0.8 (test=0.2)"
    ids = subj_df["subject_id"].values
    labels = subj_df["label"].values

    def safe_split(X, y, test_size, stratify_labels, stage_name):
        # –Ø–∫—â–æ –∑–∞–º–∞–ª–æ —Å–µ–º–ø–ª—ñ–≤ –ø–µ–≤–Ω–æ–≥–æ –∫–ª–∞—Å—É ‚Äî —Ä–æ–±–∏–º–æ –±–µ–∑ stratify
        vc = pd.Series(stratify_labels).value_counts()
        if len(vc) < 2 or (vc < 2).any():
            # –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è –º–æ–∂–Ω–∞ –≤–∏–≤–µ—Å—Ç–∏, –∞–ª–µ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç–∏ –ø—Ä–æ—Å—Ç–æ fallback
            return train_test_split(
                X, test_size=test_size, random_state=seed
            )
        else:
            return train_test_split(
                X,
                test_size=test_size,
                random_state=seed,
                stratify=stratify_labels,
            )

    # 1) train / temp
    train_ids, temp_ids = safe_split(
        ids, labels, test_size=(1.0 - train_frac), stratify_labels=labels, stage_name="train/temp"
    )

    # 2) val / test –∑ temp
    temp_df = subj_df[subj_df["subject_id"].isin(temp_ids)].copy()
    temp_labels = temp_df["label"].values
    val_size = val_frac / (val_frac + (1 - train_frac - val_frac))  # 0.2 / 0.4 = 0.5
    val_ids, test_ids = safe_split(
        temp_df["subject_id"].values,
        temp_labels,
        test_size=0.5,
        stratify_labels=temp_labels,
        stage_name="val/test",
    )

    split_map: dict[str, str] = {}
    for sid in train_ids:
        split_map[str(sid)] = "train"
    for sid in val_ids:
        split_map[str(sid)] = "val"
    for sid in test_ids:
        split_map[str(sid)] = "test"

    return split_map


def build_full_2d_index(
    nifti_root: Path,
    clinical_csv: Path,
    out_index_csv: Path,
    out_slices_root: Path,
) -> None:
    """
    –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è: –±—É–¥—É—î full 2D index –ø–æ –≤—Å—ñ—Ö —Å—É–±'—î–∫—Ç–∞—Ö.
    """
    nifti_root = nifti_root.resolve()
    out_slices_root = out_slices_root.resolve()
    out_slices_root.mkdir(parents=True, exist_ok=True)

    print(f"[INFO] NIFTI root:      {nifti_root}")
    print(f"[INFO] Clinical CSV:    {clinical_csv}")
    print(f"[INFO] Slices out root: {out_slices_root}")
    print(f"[INFO] Out index CSV:   {out_index_csv}")

    labels_map = load_clinical_labels(clinical_csv)
    print(f"[INFO] Clinical subjects with labels: {len(labels_map)}")

    subj_dirs = find_subject_dirs(nifti_root)
    print(f"[INFO] Found subject dirs: {len(subj_dirs)}")

    rows = []
    subj_label_records = []

    for subj_dir in tqdm(subj_dirs, desc="Processing subjects"):
        subject_id = subj_dir.name  # —Ç–∏–ø—É OAS1_0001_MR1

        if subject_id not in labels_map:
            # –Ω–µ–º–∞—î –∫–ª—ñ–Ω—ñ—á–Ω–æ–≥–æ –ª–µ–π–±–ª—É ‚Üí –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ
            continue
        label = labels_map[subject_id]

        img_path = choose_img_path(subj_dir)
        if img_path is None:
            print(f"[WARN] –ù–µ –∑–Ω–∞–π—à–ª–∞ –∂–æ–¥–Ω–æ–≥–æ .img –¥–ª—è {subj_dir}, –ø—Ä–æ–ø—É—Å–∫–∞—é.")
            continue

        try:
            vol = load_volume(img_path)
        except Exception as e:
            print(f"[WARN] –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ {img_path}: {e}")
            continue

        slice_paths = slice_volume_to_pngs(
            vol,
            subject_id=subject_id,
            out_root=out_slices_root,
            axis=2,
            keep_mid_fraction=0.6,
            min_dynamic_range=1e-3,
        )

        if not slice_paths:
            print(f"[WARN] –ù–µ–º–∞—î –≤–∞–ª—ñ–¥–Ω–∏—Ö —Å–ª–∞–π—Å—ñ–≤ –¥–ª—è {subject_id}, –ø—Ä–æ–ø—É—Å–∫–∞—é.")
            continue

        # –∑–∞–ø–∏—Å—É—î–º–æ —ñ–Ω–¥–µ–∫—Å –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å–ª–∞–π—Å—É (split –∑–∞–ø–æ–≤–Ω–∏–º–æ –ø—ñ–∑–Ω—ñ—à–µ)
        for sp in slice_paths:
            rows.append(
                {
                    "subject_id": subject_id,
                    "slice_path": str(sp.relative_to(out_slices_root.parent)),  # —â–æ–± —à–ª—è—Ö –±—É–≤ –≤—ñ–¥ data/
                    "label": label,
                }
            )
        subj_label_records.append({"subject_id": subject_id, "label": label})

    if not rows:
        raise RuntimeError("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∂–æ–¥–Ω–æ–≥–æ —Å–ª–∞–π—Å—É. –ü–µ—Ä–µ–≤—ñ—Ä —à–ª—è—Ö–∏ —Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–∏—Ö.")

    df = pd.DataFrame(rows)
    subj_df = pd.DataFrame(subj_label_records).drop_duplicates()

    print("[INFO] Unique subjects with volume & label:", len(subj_df))
    print("[INFO] Label counts (subjects):")
    print(subj_df["label"].value_counts())

    # —Ä–æ–±–∏–º–æ patient-level split
    split_map = stratified_split_subjects(subj_df, seed=42, train_frac=0.6, val_frac=0.2)

    df["split"] = df["subject_id"].map(split_map)

    # –º–æ–∂—É—Ç—å –±—É—Ç–∏ —Å—É–±'—î–∫—Ç–∏ –±–µ–∑ split (—è–∫—â–æ —â–æ—Å—å –ø—ñ—à–ª–æ –Ω–µ —Ç–∞–∫)
    df = df.dropna(subset=["split"]).reset_index(drop=True)

    print("[INFO] Final slice counts by split:")
    print(df["split"].value_counts())

    out_index_csv.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(out_index_csv, index=False)
    print(f"[OK] Saved index to: {out_index_csv}")


def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument(
        "--nifti_root",
        type=str,
        required=True,
        help="–ö–æ—Ä—ñ–Ω—å –∑ disc*/OAS1_XXXX_MR1 (—É —Ç–µ–±–µ: data/raw)",
    )
    ap.add_argument(
        "--clinical_csv",
        type=str,
        required=True,
        help="–®–ª—è—Ö –¥–æ oasis_cross-sectional.csv",
    )
    ap.add_argument(
        "--out_index_csv",
        type=str,
        required=True,
        help="–ö—É–¥–∏ –∑–±–µ—Ä–µ–≥—Ç–∏ CSV-—ñ–Ω–¥–µ–∫—Å (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥ data/index_oasis_full_2d.csv)",
    )
    ap.add_argument(
        "--out_slices_root",
        type=str,
        required=True,
        help="–ö—É–¥–∏ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ PNG-—Å–ª–∞–π—Å–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥ data/processed/oasis_full_2d)",
    )
    return ap.parse_args()


if __name__ == "__main__":
    args = parse_args()
    build_full_2d_index(
        nifti_root=Path(args.nifti_root),
        clinical_csv=Path(args.clinical_csv),
        out_index_csv=Path(args.out_index_csv),
        out_slices_root=Path(args.out_slices_root),
    )
